{{ $fullname :=  include "substrate_chart.name" . }}
{{range $i := until (.Values.node.replicas | int) }}
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: {{ $fullname }}
  namespace: {{ .Values.node.namespace }}
  labels:
  {{- include "substrate_node.selectorLabels" . | nindent 4 }}
spec:
  serviceName: {{ $.Values.node.peerName }}
  replicas: {{ .Values.node.replicaCount | int }}
  selector:
    matchLabels:                 
      {{- include "substrate_node.selectorLabels" . | nindent 6 }}
  updateStrategy:
    type: RollingUpdate
  template:
    metadata:
      {{- with .Values.podAnnotations }}
      annotations:
      {{- toYaml . | nindent 8 }}
      {{- end }}
      labels:               
        {{- include "substrate_node.selectorLabels" . | nindent 8 }}
    spec: 
      serviceAccountName: {{ .Values.vault.serviceaccountname }}
      initContainers:
        {{- if .Values.node.chainDataSnapshotUrl }}
      - name: download-chain-snapshot
        image: {{ .Values.initContainer.image.repository }}:{{ .Values.initContainer.image.tag }}
        command: [ "/bin/sh" ]
        args:
          - -c
          - |
            if [ -d "/data/chains/${CHAIN_PATH}/db" ]; then
              echo "Database directory already exists, skipping chain snapshot download"
            else
              echo "Downloading chain snapshot"
              SNAPSHOT_URL="{{ .Values.node.chainDataSnapshotUrl }}"
              wget -O /data/snapshot ${SNAPSHOT_URL}
              if [ ! -f /data/snapshot ]; then
                echo "Failed to download chain snapshot"
                exit 1
              fi
              mkdir -p /data/chains/${CHAIN_PATH}/
              if [ "${SNAPSHOT_FORMAT}" == "7z" ]; then
                7z x /data/snapshot -o/data/chains/${CHAIN_PATH}/
              else
                tar xvf /data/snapshot --directory=/data/chains/${CHAIN_PATH}/db/full/
              fi
              rm /data/snapshot
            fi
                    env:
        - name: CHAIN_PATH
          value: {{ default .Values.node.chain .Values.node.chainPath }}
        - name: SNAPSHOT_FORMAT
          value: {{ default "tar" .Values.node.chainDataSnapshotFormat }}
        volumeMounts:
        - mountPath: /data
          name: chain-data
        {{- end }}
        {{- if .Values.node.collator.relayChainDataSnapshotUrl }}
      - name: download-relay-chain-snapshot
        image: {{ .Values.initContainer.image.repository }}:{{ .Values.initContainer.image.tag }}
        command: [ "/bin/sh" ]
        args:
          - -c
          - |
            if [ -d "/data/relay/chains/${RELAY_CHAIN_PATH}/db" ]; then
              echo "Database directory already exists, skipping relay-chain snapshot download"
            else
              echo "Downloading relay-chain snapshot"
              RELAY_SNAPSHOT_URL="{{ .Values.node.collator.relayChainDataSnapshotUrl }}"
              wget -O /data/relay-snapshot ${RELAY_SNAPSHOT_URL}
              if [ ! -f /data/relay-snapshot ]; then
                echo "Failed to download relay-chain snapshot"
                exit 1
              fi
              mkdir -p /data/relay/chains/${RELAY_CHAIN_PATH}/
              if [ "${RELAY_SNAPSHOT_FORMAT}" == "7z" ]; then
                7z x /data/relay-snapshot -o/data/relay/chains/${RELAY_CHAIN_PATH}/
              else
                tar xvf /data/relay-snapshot --directory=/data/relay/chains/${RELAY_CHAIN_PATH}/db/full/
              fi
              rm /data/relay-snapshot
            fi
        env:
        - name: RELAY_SNAPSHOT_FORMAT
          value: {{ default "tar" .Values.node.collator.relayChainDataSnapshotFormat }}
        - name: RELAY_CHAIN_PATH
          value: {{ default .Values.node.collator.relayChain .Values.node.collator.relayChainPath }}
        volumeMounts:
        - mountPath: /data
          name: chain-data
        {{- end }}
        {{- if .Values.node.chainDataGcsBucketUrl }}
      - name: sync-chain-gcs
        image: {{ .Values.googleCloudSdk.image.repository }}:{{ .Values.googleCloudSdk.image.tag }}
        command: [ "/bin/sh" ]
        args:
          - -c
          - |
            {{- if .Values.googleCloudSdk.serviceAccountKey }}
            gcloud auth activate-service-account --key-file /tmp/service-account-key.json
            {{- end }}
            if [ -d "/data/chains/${CHAIN_PATH}/db" ]; then
              echo "Chain database directory already exists, skipping GCS sync"
            else
                BUCKET_URL="{{ .Values.node.chainDataGcsBucketUrl }}"
                LATEST=$(gsutil cat ${BUCKET_URL}/latest_version.meta.txt)
                if [ -z "$LATEST" ]; then
                  echo "Failed to retrieve latest_version metadata"
                  exit 1
                fi
                mkdir -p /data/chains/${CHAIN_PATH}/db/full
                gsutil -m -o "GSUtil:parallel_process_count=3" -o "GSUtil:parallel_thread_count=15" rsync -d -r ${BUCKET_URL}/${LATEST} /data/chains/${CHAIN_PATH}/db/full/
            fi
        env:
        - name: CHAIN_PATH
          value: {{ default .Values.node.chain .Values.node.chainPath }}
        volumeMounts:
        - mountPath: /data
          name: chain-data
          {{- if .Values.googleCloudSdk.serviceAccountKey }}
        - name: service-account-key
          mountPath: /tmp
          readOnly: true
          {{- end }}
        {{- end }}
        {{- if .Values.node.collator.relayChainDataGcsBucketUrl }}
      - name: sync-relay-chain-gcs
        image: {{ .Values.googleCloudSdk.image.repository }}:{{ .Values.googleCloudSdk.image.tag }}
        command: [ "/bin/sh" ]
        args:
          - -c
          - |
            {{- if .Values.googleCloudSdk.serviceAccountKey }}
            gcloud auth activate-service-account --key-file /tmp/service-account-key.json
            {{- end }}
            if [ -d "/data/relay/chains/${RELAY_CHAIN_PATH}/db" ]; then
              echo "Relay-chain database directory already exists, skipping GCS sync"
            else
              BUCKET_URL="{{ .Values.node.collator.relayChainDataGcsBucketUrl }}"
              LATEST=$(gsutil cat ${BUCKET_URL}/latest_version.meta.txt)
              if [ -z "$LATEST" ]; then
                echo "Failed to retrieve latest_version metadata"
                exit 1
              fi
              mkdir -p /data/relay/chains/${RELAY_CHAIN_PATH}/db/full
              gsutil -m -o "GSUtil:parallel_process_count=3" -o "GSUtil:parallel_thread_count=15" rsync -d -r ${BUCKET_URL}/${LATEST} /data/relay/chains/${RELAY_CHAIN_PATH}/db/full/
            fi
        env:
        - name: RELAY_CHAIN_PATH
          value: {{ default .Values.node.collator.relayChain .Values.node.collator.relayChainPath }}
        volumeMounts:
        - mountPath: /data
          name: chain-data
             {{- if .Values.googleCloudSdk.serviceAccountKey }}
        - name: service-account-key
          mountPath: /tmp
          readOnly: true
          {{- end }}
        {{- end }}
      - name: node-secrets
        image: {{ .Values.vault.image }}
        imagePullPolicy: IfNotPresent
        volumeMounts:
        - mountPath: /secrets
          name: keystore
        env:
        - name: VAULT_ADDR
          value: {{ .Values.vault.address }}
        - name: VAULT_SECRET_PREFIX
          value: {{ .Values.vault.secretPrefix }}
        - name: KUBERNETES_AUTH_PATH
          value: {{ .Values.vault.authPath }}
        - name: VAULT_APP_ROLE
          value: {{ .Values.vault.appRole }}
        - name: PEER_NAME
          value: {{ .Values.node.peerName }}
        command: ["/bin/sh", "-c"]
        args:
        - |-
          #!/bin/sh
            apk update && apk add jq curl
            mkdir secrets
            
            validateVaultResponse () {
              if echo ${2} | grep "errors"; then
                echo "ERROR: unable to retrieve ${1}: ${2}"
                exit 1
              fi
              if  [ "$3" == "LOOKUPSECRETRESPONSE" ]
              then
                http_code=$(curl -sS -o /dev/null -w "%{http_code}" \
                --header "X-Vault-Token: ${VAULT_CLIENT_TOKEN}" \
                ${VAULT_ADDR}/v1/${vault_secret_key})
                curl_response=$?
                if test "$http_code" != "200" ; then
                  echo "Http response code from Vault - $http_code"
                  if test "$curl_response" != "0"; then
                     echo "Error: curl command failed with error code - $curl_response"
                     exit 1
                  fi
                fi
              fi
            }

            KUBE_SA_TOKEN=$(cat /var/run/secrets/kubernetes.io/serviceaccount/token)
            echo "Getting secrets from Vault Server: ${VAULT_ADDR}"

            ## Login to Vault to get an app role token ##
            VAULT_CLIENT_TOKEN=$(curl -sS --request POST ${VAULT_ADDR}/v1/auth/${KUBERNETES_AUTH_PATH}/login \
              -H "Content-Type: application/json" \
              -d '{"role":"'"${VAULT_APP_ROLE}"'","jwt":"'"${KUBE_SA_TOKEN}"'"}' | \
              jq -r 'if .errors then . else .auth.client_token end')
            validateVaultResponse 'vault login token' "${VAULT_CLIENT_TOKEN}"
            echo "logged in"

            vault_secret_key="${VAULT_SECRET_PREFIX}/${PEER_NAME}/substrate"
            
            echo "Getting node-key, aura and grandpa secret seeds from $vault_secret_key"

            LOOKUP_SECRET_RESPONSE=$(curl -sS \
              --header "X-Vault-Token:${VAULT_CLIENT_TOKEN}" \
              ${VAULT_ADDR}/v1/${vault_secret_key} | \
              jq -r 'if .errors then . else . end')
            validateVaultResponse "secret (${vault_secret_key})" "${LOOKUP_SECRET_RESPONSE}" "LOOKUPSECRETRESPONSE" 
            
            auraSecretSeed=$(echo ${LOOKUP_SECRET_RESPONSE} | jq -r '.data.data["aura_seed"]')
            echo "${auraSecretSeed}" > secrets/aura_seed
            
            grandpaSecretSeed=$(echo ${LOOKUP_SECRET_RESPONSE} | jq -r '.data.data["grandpa_seed"]')
            echo "${grandpaSecretSeed}" > secrets/grandpa_seed
            
            node_key=$(echo ${LOOKUP_SECRET_RESPONSE} | jq -r '.data.data["node_key"]')
            echo "${node_key}" > secrets/node_key
      - name: retrieve-chain-spec
        image: {{ .Values.vault.image }}
        imagePullPolicy: IfNotPresent
        volumeMounts:
        - mountPath: /secrets
          name: keystore
        env:
        - name: VAULT_ADDR
          value: {{ .Values.vault.address }}
        - name: VAULT_SECRET_PREFIX
          value: {{ .Values.vault.secretPrefix }}
        - name: KUBERNETES_AUTH_PATH
          value: {{ .Values.vault.authPath }}
        - name: VAULT_APP_ROLE
          value: {{ .Values.vault.appRole }}
        - name: PEER_NAME
          value: {{ .Values.node.peerName }}
        command: ["/bin/sh", "-c"]
        args:
        - |-
          #!/bin/sh
            apk update && apk add jq curl
            mkdir secrets
            
            validateVaultResponse () {
              if echo ${2} | grep "errors"; then
                echo "ERROR: unable to retrieve ${1}: ${2}"
                exit 1
              fi
              if  [ "$3" == "LOOKUPSECRETRESPONSE" ]
              then
                http_code=$(curl -sS -o /dev/null -w "%{http_code}" \
                --header "X-Vault-Token: ${VAULT_CLIENT_TOKEN}" \
                ${VAULT_ADDR}/v1/${vault_secret_key})
                curl_response=$?
                if test "$http_code" != "200" ; then
                  echo "Http response code from Vault - $http_code"
                  if test "$curl_response" != "0"; then
                     echo "Error: curl command failed with error code - $curl_response"
                     exit 1
                  fi
                fi
              fi
            }

            KUBE_SA_TOKEN=$(cat /var/run/secrets/kubernetes.io/serviceaccount/token)
            echo "Getting secrets from Vault Server: ${VAULT_ADDR}"

            ## Login to Vault to get an app role token ##
            VAULT_CLIENT_TOKEN=$(curl -sS --request POST ${VAULT_ADDR}/v1/auth/${KUBERNETES_AUTH_PATH}/login \
              -H "Content-Type: application/json" \
              -d '{"role":"'"${VAULT_APP_ROLE}"'","jwt":"'"${KUBE_SA_TOKEN}"'"}' | \
              jq -r 'if .errors then . else .auth.client_token end')
            validateVaultResponse 'vault login token' "${VAULT_CLIENT_TOKEN}"
            echo "logged in"

            vault_secret_key="${VAULT_SECRET_PREFIX}/${PEER_NAME}/chainSpec"
            
            echo "Getting chain spec from $vault_secret_key"

            LOOKUP_SECRET_RESPONSE=$(curl -sS \
              --header "X-Vault-Token:${VAULT_CLIENT_TOKEN}" \
              ${VAULT_ADDR}/v1/${vault_secret_key} | \
              jq -r 'if .errors then . else . end')
            validateVaultResponse "secret (${vault_secret_key})" "${LOOKUP_SECRET_RESPONSE}" "LOOKUPSECRETRESPONSE" 
            
            chain_spec=$(echo ${LOOKUP_SECRET_RESPONSE} | jq -r '.data.data["chain_spec"]')
            echo "${chain_spec}" > secrets/chain_spec.json
      - name: inject-keys
        image: {{ .Values.image.repository }}:{{ .Values.image.tag }}
        imagePullPolicy: {{ .Values.image.pullPolicy }}
        command: ["/bin/sh", "-c"]
        args:
        - |-
          #!/bin/sh
          ## store aura and grandpa keys in node keystore ##

            exec {{ .Values.node.command }} key insert --base-path /data \
            --chain secrets/chain_spec.json \
            --scheme Sr25519 \
            --suri secrets/aura_seed \
            --key-type aura

            exec {{ .Values.node.command }} key insert --base-path /data \
            --chain secrets/chain_spec.json \
            --scheme Ed25519 \
            --suri secrets/grandpa_seed \
            --key-type gran
        volumeMounts:
        - mountPath: /secrets
          name: keystore
        - mountPath: /data
          name: chain-data
        {{- if .Values.node.perNodeServices.createP2pNodePortService }}
      - name: retrieve-node-port
        image: {{ .Values.kubectl.image.repository }}:{{ .Values.kubectl.image.tag }}
        command: [ "/bin/sh" ]
        args:
          - -c
          - |
            POD_INDEX="${HOSTNAME##*-}"
            RELAY_CHAIN_P2P_PORT="$(kubectl --namespace {{ .Release.Namespace }} get service {{ $fullname }}-${POD_INDEX}-relay-chain-p2p -o jsonpath='{.spec.ports[*].nodePort}')"
            echo "${RELAY_CHAIN_P2P_PORT}" > /data/relay_chain_p2p_port
            echo "Retrieved Kubernetes service node port from {{ $fullname }}-${POD_INDEX}-relay-chain-p2p, saved ${RELAY_CHAIN_P2P_PORT} to /data/relay_chain_p2p_port"
            {{- if .Values.node.collator.isParachain }}
            PARA_CHAIN_P2P_PORT="$(kubectl --namespace {{ .Release.Namespace }} get service {{ $fullname }}-${POD_INDEX}-para-chain-p2p -o jsonpath='{.spec.ports[*].nodePort}')"
            echo "${PARA_CHAIN_P2P_PORT}" > /data/para_chain_p2p_port
            echo "Retrieved Kubernetes service node port from {{ $fullname }}-${POD_INDEX}-para-chain-p2p, saved ${PARA_CHAIN_P2P_PORT} to /data/para_chain_p2p_port"
            {{- end }}
            {{- if .Values.node.perNodeServices.setPublicAddressToExternalIp.enabled }}
            EXTERNAL_IP=$(curl {{ .Values.node.perNodeServices.setPublicAddressToExternalIp.ipRetrievalServiceUrl }})
            echo "${EXTERNAL_IP}" > /data/node_external_ip
            echo "Retrieved external IP from {{ .Values.node.perNodeServices.setPublicAddressToExternalIp.ipRetrievalServiceUrl }}, saved ${EXTERNAL_IP} to /data/node_external_ip"
            {{- end }}
        volumeMounts:
        - mountPath: /data
          name: chain-data
        {{- end }}
      containers:
      - name: {{ .Values.node.chain }}
        image: {{ .Values.image.repository }}:{{ .Values.image.tag }}
        imagePullPolicy: {{ .Values.image.pullPolicy }}
        command: ["/bin/sh", "-c"]
        args:
        - |-
          #!/bin/sh
              {{- if .Values.node.perNodeServices.createP2pNodePortService }}
              {{- if .Values.node.perNodeServices.setPublicAddressToExternalIp.enabled }}
              EXTERNAL_IP="$(cat /data/node_external_ip)"
              echo "EXTERNAL_IP=${EXTERNAL_IP}"
              {{- end }}
              RELAY_CHAIN_P2P_PORT="$(cat /data/relay_chain_p2p_port)"
              echo "RELAY_CHAIN_P2P_PORT=${RELAY_CHAIN_P2P_PORT}"
              {{- if .Values.node.collator.isParachain }}
              PARA_CHAIN_P2P_PORT="$(cat /data/para_chain_p2p_port)"
              echo "PARA_CHAIN_P2P_PORT=${PARA_CHAIN_P2P_PORT}"
              {{- end }}
              {{- end }}
            exec {{ .Values.node.command }} \
            --chain secrets/chain_spec.json \
            --name=${POD_NAME} \
            --base-path=/data/ \
            {{- if or (eq .Values.node.role "authority") (eq .Values.node.role "validator") }}
            --validator \
            {{- end }}
            {{- if eq .Values.node.role "collator" }}
            --collator \
            {{- end }}
            {{- if eq .Values.node.role "light" }}
            --light \
            {{- end }}
            {{- if or (eq .Values.node.role "validator") (eq .Values.node.role "member") }}
            --bootnodes {{ .Values.bootnode }}\
            {{- end }}
            {{- if .Values.node.collator.isParachain }}
            {{- if .Values.node.perNodeServices.createP2pNodePortService }}
            {{- if .Values.node.perNodeServices.setPublicAddressToExternalIp.enabled }}
            --public-addr=/ip4/${EXTERNAL_IP}/tcp/${PARA_CHAIN_P2P_PORT} \
            {{- end }}
            --listen-addr=/ip4/0.0.0.0/tcp/${PARA_CHAIN_P2P_PORT} \
            {{- end }}
            --listen-addr=/ip4/0.0.0.0/tcp/30334 \
            {{- end }}
            {{- if .Values.node.persistGeneratedNodeKey }}
            --node-key-file /data/node-key \
            {{- else if .Values.node.customNodeKey }}
            --node-key $(cat secrets/node_key) \
            {{- end }}
            {{- if .Values.node.tracing.enabled }}
            --jaeger-agent=127.0.0.1:{{ .Values.jaegerAgent.ports.compactPort }} \
            {{- end }}
            {{- join " " .Values.node.flags | nindent 12 }}
            {{- if .Values.node.collator.isParachain }} \
            -- \
            --base-path=/data/relay/ \
            {{- end }}
            {{- if .Values.node.collator.relayChainCustomChainspecUrl }}
            --chain=/data/relay_chain_chainspec.json \
            {{- end }}
            {{- if .Values.node.perNodeServices.createP2pNodePortService }}
            {{- if .Values.node.perNodeServices.setPublicAddressToExternalIp.enabled }}
            --public-addr=/ip4/${EXTERNAL_IP}/tcp/${RELAY_CHAIN_P2P_PORT} \
            {{- end }}
            --listen-addr=/ip4/0.0.0.0/tcp/${RELAY_CHAIN_P2P_PORT} \
            {{- end }}
            --listen-addr=/ip4/0.0.0.0/tcp/30333 \
            {{- join " " .Values.node.collator.relayChainFlags | nindent 12 }}
        env:
        - name: NODE_NAME
          value: "$(POD_NAME)"
        - name: POD_NAME
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: metadata.name
        ports:
          - name: ws-rpc
            containerPort: {{ .Values.node.ports.ws }}
            protocol: TCP
          - name: p2p
            containerPort: {{ .Values.node.ports.p2p }}
            protocol: TCP
          - name: http-rpc
            containerPort: {{ .Values.node.ports.rpc }}
            protocol: TCP
          - name: prometheus 
            containerPort: 9615
            protocol: TCP
        
        {{- if .Values.node.enableStartupProbe }}
          # On startup, retry the connection to the /health endpoint every 10s for 5 min before killing the container
        startupProbe:
          failureThreshold: 30
          periodSeconds: 10
          httpGet:
            path: /health
            port: http-rpc
        {{- end }}
        {{- if .Values.node.enableReadinessProbe }}
          # Continuously retry the connection to the WS endpoint every 10s for 24h until success before marking the container as ready
          # If the WS endpoint is still not reachable (ie. node not fully synced) after 24 hours have passed, the container will be stuck in 'Not Ready' state
        readinessProbe:
          failureThreshold: 8640
          initialDelaySeconds: 10
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 1
          # Important: the readiness probe will only work properly if the WS endpoint is exposed with --ws-external
          tcpSocket:
            port: websocket-rpc
        {{- end }}
        resources:
          {{- toYaml .Values.node.resources | nindent 12 }}
        volumeMounts:
        - mountPath: /secrets
          name: keystore
        - mountPath: /data
          name: chain-data
      {{- if .Values.node.substrateApiSidecar.enabled }}
      - name: substrate-api-sidecar
        image: {{ .Values.substrateApiSidecar.image.repository }}:{{ .Values.substrateApiSidecar.image.tag }}
        env:
          {{- range $key, $val := .Values.substrateApiSidecar.env }}
        - name: {{ $key }}
          value: {{ $val }}
          {{- end }}
        resources:
        {{- toYaml .Values.substrateApiSidecar.resources | nindent 12 }}
        ports:
          - containerPort: 8080
            name: api-sidecar
            protocol: TCP
        {{- end}}
        {{- if .Values.node.tracing.enabled }}
      - name: jaeger-agent-sidecar
        image: {{ .Values.jaegerAgent.image.repository }}:{{ .Values.jaegerAgent.image.tag }}
        args:
          - --reporter.grpc.host-port={{ .Values.jaegerAgent.collector.url }}:{{ .Values.jaegerAgent.collector.port }}
        env:
        {{- range $key, $val := .Values.jaegerAgent.env }}
        - name: {{ $key }}
          value: {{ $val }}
        {{- end }}
        resources:
        {{- toYaml .Values.jaegerAgent.resources | nindent 12 }}
        ports:
        - name: jaeger-compact
          containerPort: {{ .Values.jaegerAgent.ports.compactPort }}
          protocol: UDP
        - name: jaeger-binary
          containerPort: {{ .Values.jaegerAgent.ports.binaryPort }}
          protocol: UDP
        - name: http
          containerPort: {{ .Values.jaegerAgent.ports.samplingPort }}
          protocol: TCP
        - name: admin
          containerPort: 14271
          protocol: TCP
        livenessProbe:
          httpGet:
            path: /
            port: admin
        readinessProbe:
          httpGet:
            path: /
            port: admin
      {{- end}}
      serviceAccountName: {{ $serviceAccountName }}
      securityContext:
      {{- toYaml .Values.podSecurityContext | nindent 8 }}
      terminationGracePeriodSeconds: {{ .Values.terminationGracePeriodSeconds }}
      {{- with .Values.nodeSelector }}
      nodeSelector:
      {{- toYaml . | nindent 10 }}
      {{- end }}
      {{- with .Values.affinity }}
      affinity:
      {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- with .Values.tolerations }}
      tolerations:
      {{- toYaml . | nindent 8 }}
      {{- end }}
      volumes:
      {{- if .Values.googleCloudSdk.serviceAccountKey }}
      - name: service-account-key
        secret:
          secretName: chain-data-gcs-bucket-service-account-key
      {{- end }}
      - name: keystore
        emptyDir:
          medium: Memory
      restartPolicy: OnFailure
  volumeClaimTemplates:
    - apiVersion: v1
      kind: PersistentVolumeClaim
      metadata:
        name: chain-data
      spec:
        accessModes: [ "ReadWriteOnce" ]
        {{- if .Values.node.chainDataKubernetesVolumeSnapshot }}
        dataSource:
          name: {{ .Values.node.chainDataKubernetesVolumeSnapshot }}
          kind: VolumeSnapshot
          apiGroup: snapshot.storage.k8s.io
        {{- end }}
        storageClassName: {{ .Values.storageClass }}
        resources:
          requests:
            storage: {{ .Values.node.dataVolumeSize }}
